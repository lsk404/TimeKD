Namespace(device='cuda:0', root_path='./data/ETT-small/ETT-small/', data_path='ETTh1', channel=64, num_nodes=7, seq_len=96, pred_len=24, batch_size=16, lrate=0.0001, dropout_n=0.5, d_llm=768, e_layer=2, head=4, model_path='./gpt2_model', tokenizer_path='./gpt2_tokenizer', weight_decay=0.001, feature_w=0.01, fcst_w=1, recon_w=0.5, att_w=0.01, num_workers=10, epochs=100, seed=6666, es_patience=50, save='./logs/2025-08-05-04:48:41-', num_users=100, frac=0.1, local_ep=5, local_bs=10, bs=32, all_clients=False, verbose=False, threshold=1, Temperature=1)
The number of parameters: 1711792
Dual(
  (normalize_layers): Normalize()
  (length_to_feature): Linear(in_features=96, out_features=64, bias=True)
  (token_to_feature): Linear(in_features=768, out_features=64, bias=True)
  (ts_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (ts_proj): Linear(in_features=64, out_features=24, bias=True)
  (prompt_proj): Linear(in_features=64, out_features=24, bias=True)
)
Start training...
Traceback (most recent call last):
  File "/root/TimeKD/train_fed_D.py", line 427, in <module>
    main()
  File "/root/TimeKD/train_fed_D.py", line 245, in main
    w, train_loss,train_mse,train_mae,gradients = local.train(local_model=copy.deepcopy(engine))
  File "/root/TimeKD/fed/update.py", line 45, in train
    trainx = torch.Tensor(x).to(device).float()
RuntimeError: CUDA error: no kernel image is available for execution on the device
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Namespace(device='cuda:0', root_path='./data/ETT-small/ETT-small/', data_path='ETTh1', channel=64, num_nodes=7, seq_len=96, pred_len=24, batch_size=16, lrate=0.0001, dropout_n=0.5, d_llm=768, e_layer=2, head=4, model_path='./gpt2_model', tokenizer_path='./gpt2_tokenizer', weight_decay=0.001, feature_w=0.01, fcst_w=1, recon_w=0.5, att_w=0.01, num_workers=10, epochs=100, seed=6666, es_patience=50, save='./logs/2025-08-05-04:48:45-', num_users=100, frac=0.1, local_ep=5, local_bs=10, bs=32, all_clients=False, verbose=False, threshold=1, Temperature=1)
The number of parameters: 1711792
Dual(
  (normalize_layers): Normalize()
  (length_to_feature): Linear(in_features=96, out_features=64, bias=True)
  (token_to_feature): Linear(in_features=768, out_features=64, bias=True)
  (ts_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (ts_proj): Linear(in_features=64, out_features=24, bias=True)
  (prompt_proj): Linear(in_features=64, out_features=24, bias=True)
)
Start training...
Traceback (most recent call last):
  File "/root/TimeKD/train_fed_D.py", line 427, in <module>
    main()
  File "/root/TimeKD/train_fed_D.py", line 245, in main
    w, train_loss,train_mse,train_mae,gradients = local.train(local_model=copy.deepcopy(engine))
  File "/root/TimeKD/fed/update.py", line 45, in train
    trainx = torch.Tensor(x).to(device).float()
RuntimeError: CUDA error: no kernel image is available for execution on the device
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Namespace(device='cuda:0', root_path='./data/ETT-small/ETT-small/', data_path='ETTh1', channel=64, num_nodes=7, seq_len=96, pred_len=24, batch_size=16, lrate=0.0001, dropout_n=0.5, d_llm=768, e_layer=2, head=4, model_path='./gpt2_model', tokenizer_path='./gpt2_tokenizer', weight_decay=0.001, feature_w=0.01, fcst_w=1, recon_w=0.5, att_w=0.01, num_workers=10, epochs=100, seed=6666, es_patience=50, save='./logs/2025-08-05-04:48:49-', num_users=100, frac=0.1, local_ep=5, local_bs=10, bs=32, all_clients=False, verbose=False, threshold=1, Temperature=1)
The number of parameters: 1711792
Dual(
  (normalize_layers): Normalize()
  (length_to_feature): Linear(in_features=96, out_features=64, bias=True)
  (token_to_feature): Linear(in_features=768, out_features=64, bias=True)
  (ts_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (ts_proj): Linear(in_features=64, out_features=24, bias=True)
  (prompt_proj): Linear(in_features=64, out_features=24, bias=True)
)
Start training...
Traceback (most recent call last):
  File "/root/TimeKD/train_fed_D.py", line 427, in <module>
    main()
  File "/root/TimeKD/train_fed_D.py", line 245, in main
    w, train_loss,train_mse,train_mae,gradients = local.train(local_model=copy.deepcopy(engine))
  File "/root/TimeKD/fed/update.py", line 45, in train
    trainx = torch.Tensor(x).to(device).float()
RuntimeError: CUDA error: no kernel image is available for execution on the device
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Namespace(device='cuda:0', root_path='./data/ETT-small/ETT-small/', data_path='ETTh1', channel=64, num_nodes=7, seq_len=96, pred_len=24, batch_size=16, lrate=0.0001, dropout_n=0.5, d_llm=768, e_layer=2, head=4, model_path='./gpt2_model', tokenizer_path='./gpt2_tokenizer', weight_decay=0.001, feature_w=0.01, fcst_w=1, recon_w=0.5, att_w=0.01, num_workers=10, epochs=100, seed=6666, es_patience=50, save='./logs/2025-08-05-04:48:52-', num_users=100, frac=0.1, local_ep=5, local_bs=10, bs=32, all_clients=False, verbose=False, threshold=1, Temperature=1)
The number of parameters: 1711792
Dual(
  (normalize_layers): Normalize()
  (length_to_feature): Linear(in_features=96, out_features=64, bias=True)
  (token_to_feature): Linear(in_features=768, out_features=64, bias=True)
  (ts_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (ts_proj): Linear(in_features=64, out_features=24, bias=True)
  (prompt_proj): Linear(in_features=64, out_features=24, bias=True)
)
Start training...
Traceback (most recent call last):
  File "/root/TimeKD/train_fed_D.py", line 427, in <module>
    main()
  File "/root/TimeKD/train_fed_D.py", line 245, in main
    w, train_loss,train_mse,train_mae,gradients = local.train(local_model=copy.deepcopy(engine))
  File "/root/TimeKD/fed/update.py", line 45, in train
    trainx = torch.Tensor(x).to(device).float()
RuntimeError: CUDA error: no kernel image is available for execution on the device
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Namespace(device='cuda:0', root_path='./data/ETT-small/ETT-small/', data_path='ETTh1', channel=64, num_nodes=7, seq_len=96, pred_len=24, batch_size=16, lrate=0.0001, dropout_n=0.5, d_llm=768, e_layer=2, head=4, model_path='./gpt2_model', tokenizer_path='./gpt2_tokenizer', weight_decay=0.001, feature_w=0.01, fcst_w=1, recon_w=0.5, att_w=0.01, num_workers=10, epochs=100, seed=6666, es_patience=50, save='./logs/2025-08-05-04:48:55-', num_users=100, frac=0.1, local_ep=5, local_bs=10, bs=32, all_clients=False, verbose=False, threshold=1, Temperature=1)
The number of parameters: 1711792
Dual(
  (normalize_layers): Normalize()
  (length_to_feature): Linear(in_features=96, out_features=64, bias=True)
  (token_to_feature): Linear(in_features=768, out_features=64, bias=True)
  (ts_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (prompt_encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.5, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 3072, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(3072, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (ts_proj): Linear(in_features=64, out_features=24, bias=True)
  (prompt_proj): Linear(in_features=64, out_features=24, bias=True)
)
Start training...
Traceback (most recent call last):
  File "/root/TimeKD/train_fed_D.py", line 427, in <module>
    main()
  File "/root/TimeKD/train_fed_D.py", line 245, in main
    w, train_loss,train_mse,train_mae,gradients = local.train(local_model=copy.deepcopy(engine))
  File "/root/TimeKD/fed/update.py", line 45, in train
    trainx = torch.Tensor(x).to(device).float()
RuntimeError: CUDA error: no kernel image is available for execution on the device
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

